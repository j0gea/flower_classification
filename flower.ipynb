{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/letddo/flower_classification/blob/main/flower.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSwb2A8k_m1_"
      },
      "source": [
        "## 참고 자료\n",
        "\n",
        "- kaggle api colab으로 사용하기 - https://colab.research.google.com/github/corrieann/kaggle/blob/master/kaggle_api_in_colab.ipynb\n",
        "\n",
        "- image to dataset - https://towardsdatascience.com/loading-custom-image-dataset-for-deep-learning-models-part-1-d64fa7aaeca6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zq5NQccEdk7"
      },
      "source": [
        "### 1. kaggle api colab으로 사용하기\n",
        "- 이제 다운도 안받아도 된다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZkjwSQNQJhO"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "pI1zHSkmUpvr",
        "outputId": "43383e03-7837-4fcf-83ad-17efdbf014d2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a3edd114-2b79-4c84-8683-0fc42880731c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a3edd114-2b79-4c84-8683-0fc42880731c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"baksuhyun\",\"key\":\"f5270d215c416a5b097995b6b23d4a86\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from google.colab import files \n",
        "files.upload() # kaggle 홈페이지 > 오른쪽 위 프로필 > Settings > Create new token 해서 다운받은 json 파일\n",
        "# 본인 '각자' 다른 파일을 넣어줘야 합니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROtecG_IWLZ4"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle \n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8irHbfcsXNBr",
        "outputId": "475e364b-e529-442b-a571-f72c59fac915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading flower-classification-5-classes-roselilyetc.zip to /content\n",
            "100% 948M/949M [00:47<00:00, 22.6MB/s]\n",
            "100% 949M/949M [00:47<00:00, 21.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "! kaggle datasets download -d utkarshsaxenadn/flower-classification-5-classes-roselilyetc\n",
        "# kaggle competitions download -c tpu-getting-started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLBwoPYoYZDk"
      },
      "outputs": [],
      "source": [
        "!unzip flower-classification-5-classes-roselilyetc.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yWv5a1JAMTc"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtjkoN1mEo6F"
      },
      "source": [
        "### 2. 데이터 다루기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym254fo__714"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.models import Sequential, Model\n",
        "from keras.applications.resnet import ResNet50, preprocess_input\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8033ERdA0Mc"
      },
      "outputs": [],
      "source": [
        "# 경로 체크 용\n",
        "\n",
        "img = mpimg.imread('/content/Flower Classification/Flower Classification/Training Data/Daisy/Daisy (1).jpeg')\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ADrq24LBfYQ"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH=224\n",
        "IMG_HEIGHT=224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ua-HkHBRCFoO"
      },
      "outputs": [],
      "source": [
        "# img -> dataset 함수\n",
        "def create_dataset(img_folder):\n",
        "   \n",
        "    img_data_array=[]\n",
        "    class_name=[]\n",
        "   \n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "       \n",
        "            image_path= os.path.join(img_folder, dir1,  file)\n",
        "            image= cv2.imread(image_path) \n",
        "            b, g, r = cv2.split(image)\n",
        "            image = cv2.merge([r,g,b])\n",
        "            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "            image=np.array(image)\n",
        "            image = image.astype('float32')\n",
        "            image /= 255 \n",
        "            img_data_array.append(image)\n",
        "            class_name.append(dir1)\n",
        "        \n",
        "        print(\"Done \" + dir1)\n",
        "    \n",
        "    \n",
        "    target_dict={k: v for v, k in enumerate(np.unique(class_name))} \n",
        "    target_val=[target_dict[class_name[i]] for i in range(len(class_name))] \n",
        "    img_data_array = np.array(img_data_array) # araay -> nparray로 바꾸는 과정 \n",
        "    return img_data_array, target_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRxt7_KvChHE",
        "outputId": "3f86f945-7beb-4269-e6df-381bbd3fb5e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Rose\n",
            "Done Daisy\n",
            "Done Lavender\n",
            "Done Lily\n",
            "Done Sunflower\n",
            "Done Rose\n",
            "Done Daisy\n",
            "Done Lavender\n",
            "Done Lily\n",
            "Done Sunflower\n",
            "Done Rose\n",
            "Done Daisy\n",
            "Done Lavender\n",
            "Done Lily\n",
            "Done Sunflower\n"
          ]
        }
      ],
      "source": [
        "x_train, t_train =create_dataset('/content/Flower Classification/Flower Classification/Training Data')\n",
        "x_test, t_test =create_dataset('/content/Flower Classification/Flower Classification/Testing Data')\n",
        "x_val, t_val =create_dataset('/content/Flower Classification/Flower Classification/Validation Data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2yaYbwwCz1Y"
      },
      "outputs": [],
      "source": [
        "# data test\n",
        "\n",
        "label_names = ['Daisy', 'Lavender', 'Lily', 'Rose', 'Sunflower']\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "for i in range(25):\n",
        "    l = random.randrange(1,5000)\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(x_train[l])\n",
        "    plt.xlabel(label_names[t_train[l]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRDsla03C3tE",
        "outputId": "c2f4accc-3721-4316-b1c5-9a46baf53639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot Vector 적용 후 t_val shape :  (2500, 5)\n",
            "One-hot Vector 적용 후 t_train shape :  (5000, 5)\n",
            "One-hot Vector 적용 후 t_test shape :  (958, 5)\n"
          ]
        }
      ],
      "source": [
        "t_train = to_categorical(t_train)\n",
        "t_test = to_categorical(t_test)\n",
        "t_val = to_categorical(t_val)\n",
        "print('One-hot Vector 적용 후 t_val shape : ', t_val.shape)\n",
        "print('One-hot Vector 적용 후 t_train shape : ', t_train.shape)\n",
        "print('One-hot Vector 적용 후 t_test shape : ', t_test.shape)\n",
        "\n",
        "# 적용을 하지 않으면 아무래도 list 상태인 것 같다 "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (0) 데이터 늘리기 beta\n",
        "\n",
        "- 문제점: 메모리오류 / 수정할 것: 쪼개서 추가하기\n",
        "- 사용할때 위의 코드에서 train dataset을 만드는 과정은 주석처리하고 사용해주시는게 좋습니다."
      ],
      "metadata": {
        "id": "0DoB1ts43vxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "mFy6GoQe3veQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#augmentation이 적용된 image들을 시각화 해주는 함수\n",
        "def show_aug_image(image, generator):\n",
        "\t\n",
        "    # ImageDataGenerator는 여러개의 image를 입력으로 받기 때문에 4차원으로 입력 해야함.\n",
        "    image_batch = np.expand_dims(image, axis=0)\n",
        "    generator.fit(image_batch) \n",
        "\n",
        "    return image_batch\n",
        "\n",
        "\n",
        "data_generator = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=(0.7, 1.3),\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    #rescale=1/255.0 # 학습시 적용, 시각화를 위해 임시로 주석처리\n",
        ")\n"
      ],
      "metadata": {
        "id": "xd9ySDcc4L7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img -> dataset 제너레이트 하면서 \n",
        "def create_dataset_with_g(img_folder):\n",
        "   \n",
        "    img_data_array=[]\n",
        "    class_name=[]\n",
        "   \n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "       \n",
        "            image_path= os.path.join(img_folder, dir1,  file)\n",
        "            image= cv2.imread(image_path) \n",
        "            b, g, r = cv2.split(image)\n",
        "            image = cv2.merge([r,g,b])\n",
        "            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "            image=np.array(image)\n",
        "            image = image.astype('float32')\n",
        "            image /= 255 \n",
        "            img_data_array.append(image)\n",
        "            class_name.append(dir1)\n",
        "\n",
        "            for i in range(4):\n",
        "              for l in show_aug_image(image, data_generator):\n",
        "                img_data_array.append(l)\n",
        "                class_name.append(dir1)\n",
        "\n",
        "\n",
        "        print(\"Done \" + dir1)\n",
        "    \n",
        "    \n",
        "    target_dict={k: v for v, k in enumerate(np.unique(class_name))} \n",
        "    target_val=[target_dict[class_name[i]] for i in range(len(class_name))] \n",
        "    img_data_array = np.array(img_data_array) # araay -> nparray로 바꾸는 과정 \n",
        "    return img_data_array, target_val"
      ],
      "metadata": {
        "id": "otX1ToofteNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, t_train =create_dataset_with_g('./Flower Classification/Flower Classification/Training Data')"
      ],
      "metadata": {
        "id": "KysRdJXQ4M46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_train = to_categorical(t_train)\n",
        "print('One-hot Vector 적용 후 t_train shape : ', t_train.shape)"
      ],
      "metadata": {
        "id": "2NztJSyu4hKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (0-1) 웹 크롤링"
      ],
      "metadata": {
        "id": "9F1UtM0B-gTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- pixabay API - https://www.youtube.com/watch?v=vzvnGT6-gPA)\n",
        "- https://pixabay.com/api/docs/\n",
        "\n",
        "- 웹 크롤링 - https://kimcoder.tistory.com/259"
      ],
      "metadata": {
        "id": "_Ns0VgpP-8A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "# import key"
      ],
      "metadata": {
        "id": "krc-BKOL-oyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key = ' ' # 님들꺼 받아쓰셈 픽사베이에서\n",
        "keyword = 'daisy'\n",
        "pages = 2 # 한 페이지당 20"
      ],
      "metadata": {
        "id": "KS0oYiPG--kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = './crawled_img/'+ keyword + '/'\n",
        "\n",
        "# './crawled_img/'+keyword+'_'+str(maxImages)\n",
        "\n",
        "try:\n",
        "    # 중복되는 폴더 명이 없다면 생성\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "    # 중복된다면 문구 출력 후 프로그램 종료\n",
        "    else:\n",
        "        print('이전에 같은 [검색어, 이미지 수]로 다운로드한 폴더가 존재합니다.')\n",
        "        sys.exit(0)\n",
        "except OSError:\n",
        "    print ('os error')\n",
        "    sys.exit(0)"
      ],
      "metadata": {
        "id": "kXtJhe8f_NjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for page in range(1,int(pages)+1):\n",
        "    url = 'https://pixabay.com/api/?key='+key+'&q=' +keyword+'&image_type=photo&page='+str(page)\n",
        "    \n",
        "    r = requests.get(url)\n",
        "    json_data = r.json()\n",
        "    \n",
        "    for image in json_data['hits']:\n",
        "        name = image['id']\n",
        "        img_url = image['previewURL'] # largeImageURL(대) webformatURL(중) previewURL(소)\n",
        "        r = requests.get(img_url, stream=True)\n",
        "        with open(path + keyword + '(' + str(name) + ').jpg', 'wb') as f:\n",
        "            f.write(r.content)"
      ],
      "metadata": {
        "id": "Q6hVPraZ_OZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (0-2) Image 분류기\n"
      ],
      "metadata": {
        "id": "ZcFVZZPIDcJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from os import remove\n",
        "from  matplotlib import pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "\n",
        "# 모델 불러오기\n",
        "model2 = keras.models.load_model('C:\\model/ResNet152v2_b64_e10.h5') # 88% 정확도\n",
        "# 오류가 나면 '한글' 경로가 없는 절대경로로 입력해주세요 "
      ],
      "metadata": {
        "id": "e9nwI8WsDkaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_folder = './Flower Classification_/Flower Classification/Training Data/Daisy' # 수정할 이미지 폴더 # Validation Data Testing Data\n",
        "\n",
        "img_label = 'Daisy' # 수정할 이미지의 라벨(이름) 'Daisy', 'Lavender', 'Lily', 'Rose', 'Sunflower'\n",
        "move_folder = './change/' + img_label +'/' # 이동할 이미지 폴더\n",
        "os.makedirs(move_folder) # 폴더가 이미 존재하면 실행 X\n",
        "\n",
        "amount = 1.8986970e-09 # 1.8986970e-09  1.2831312e-10 # 기준값. 건드리지 않는게 좋음\n",
        "IMG_WIDTH=224\n",
        "IMG_HEIGHT=224 "
      ],
      "metadata": {
        "id": "sfhwOMArDrs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = ['Daisy', 'Lavender', 'Lily', 'Rose', 'Sunflower']\n",
        "\n",
        "\n",
        "worng = 0\n",
        "all_img = len(os.listdir(img_folder))\n",
        "\n",
        "print('총 파일 수: ', all_img, '\\n이미지 분류 시작\\n')\n",
        "\n",
        "for file in os.listdir(img_folder):\n",
        "    # all_img += 1\n",
        "    image_path= os.path.join(img_folder, file)\n",
        "    image= cv2.imread(image_path) \n",
        "    b, g, r = cv2.split(image)\n",
        "    image = cv2.merge([r,g,b])\n",
        "    image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "    image=np.array(image)\n",
        "    image = image.astype('float32')\n",
        "    image /= 255 \n",
        "    \n",
        "    output = model2.predict(image.reshape(1, IMG_WIDTH, IMG_WIDTH, 3), verbose=0) # 되려나\n",
        "\n",
        "    if(output[0][0] + output[0][1] + output[0][2] + output[0][3] + output[0][4] - output[0][label_names.index(img_label)]  > amount or\n",
        "       label_names[np.argmax(output)] != img_label):\n",
        "        \n",
        "        \n",
        "        worng +=1\n",
        "        plt.figure(figsize=(2,2))\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.imshow(image.reshape(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "        \n",
        "        print('잘못된 이미지['+ file + ']\\n예측 : ' + label_names[np.argmax(output)] + ' / 정답 : ' + img_label, \"\\n\", output)\n",
        "        plt.show()\n",
        "        # remove(file) # 삭제\n",
        "        \n",
        "        shutil.move(img_folder + '/' + file, move_folder + file)\n",
        "\n",
        "print('잘못된 이미지 개수: ', worng, \"/\",  all_img)"
      ],
      "metadata": {
        "id": "db4qVozZDxtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4nUY_ogXmAh"
      },
      "source": [
        "## (1) 기존 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vGNUB8dE5ae"
      },
      "source": [
        "### 3. model 부분"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfqW9ie8DJKN"
      },
      "outputs": [],
      "source": [
        "# model 부분 \n",
        "\n",
        "width = 200\n",
        "height = 200\n",
        "channel = 3\n",
        "\n",
        "model = Sequential(name = 'CIFAR10_CNN')\n",
        "\n",
        "model.add(Conv2D(filters=100, kernel_size=(2, 2), padding= 'same', activation= 'relu',\n",
        "                input_shape=(width, height, channel)))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=200, kernel_size=(2, 2), padding= 'same', activation= 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=400, kernel_size=(2, 2), padding= 'same', activation= 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate = 0.001), metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sduZTV9E-e0"
      },
      "source": [
        "### 4. 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NE7DrQqDV8a"
      },
      "outputs": [],
      "source": [
        "# 학습하기\n",
        "model.fit(x_train, t_train, epochs=10, batch_size=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F69qo5-XFC0k"
      },
      "source": [
        "### 5. 성능 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwHOGVpBDgjz"
      },
      "outputs": [],
      "source": [
        "# 성능 확인\n",
        "width = 200\n",
        "height = 200\n",
        "channel = 3\n",
        "\n",
        "label_names = ['Daisy', 'Lavender', 'Lily', 'Rose', 'Sunflower']\n",
        "\n",
        "for i in range(10):\n",
        "    plt.figure(figsize=(2,2))\n",
        "\n",
        "    l = random.randrange(1,900)\n",
        "    \n",
        "    output = model.predict(x_test[l].reshape(1, width, height, channel))\n",
        "    \n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(x_test[l].reshape(width, height, channel))\n",
        "    \n",
        "    print('예측 : ' + label_names[np.argmax(output)] + ' / 정답 : ' + label_names[np.argmax(t_test[l])])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qz_3QrIfDhia"
      },
      "outputs": [],
      "source": [
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(x_test, t_test, verbose=1)\n",
        "print('test loss : ', round(loss, 6))\n",
        "print('test accuracy : ', round(accuracy*100, 3), '%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg-9TEshXskC"
      },
      "source": [
        "## (2) 강의 실습 모델1: ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rW4vRBy4jkw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b94af0-f058-46f5-9dcf-77d12b3ca738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(200,200,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqJ06JQi47_8"
      },
      "outputs": [],
      "source": [
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "predictions = Dense(5, activation='softmax')(x) # Dense = 클래스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tA4SAhhX52WA"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVKJnu8f62qM"
      },
      "outputs": [],
      "source": [
        "for layer in base_model.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7DuyO7y68KF"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# if one-hot -> loss = 'categorical_crossentropy'\n",
        "# 1D or 정수 인코딩 대상 = sparse_categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2EnXzdz7GvG"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ModelCheckpoint\n",
        "- https://blog.naver.com/combioai/221468928164"
      ],
      "metadata": {
        "id": "fH4CbqMrhZIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                           patience=5),\n",
        "             keras.callbacks.ModelCheckpoint(filepath='C:\\model/best_model.h5', # 적당한 폴더에 사용하길 바람\n",
        "                                             monitor='val_loss',\n",
        "                                             save_best_only=True)]"
      ],
      "metadata": {
        "id": "wxFDrG7thYrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HiTFKhA7Pb6"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train, t_train, batch_size= 64, epochs=10, validation_data=(x_val, t_val), callbacks=callbacks)\n",
        "#  callbacks=[early_stopping] 기존방식\n",
        "#  callbacks ModelCheckpoint 방식"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('C:\\model/best_model.h5') # 절대경로로 작성해야 오류가 적음"
      ],
      "metadata": {
        "id": "UfFfkEtds8II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5HdcZXndpzl"
      },
      "outputs": [],
      "source": [
        "# 불러오기\n",
        "\n",
        "# 학습을 시키지 않아도 됨 \n",
        "from keras.models import load_model\n",
        "model2 = load_model('/content/ResNet50_1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bARpnF0eFOV"
      },
      "source": [
        "GoogleNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTsrA9TseEdx"
      },
      "outputs": [],
      "source": [
        "from keras.applications import inception_v3\n",
        "model = inception_v3.InceptionV3(weights='imagenet', include_top=True)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtf4mOd2e1Ee"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8r0s8nNuSU8"
      },
      "source": [
        "## (2) 강의 실습 모델3: VGG19Net\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HuQ1i_OuvD3"
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg19 import VGG19\n",
        "tf.keras.applications.VGG19(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "model=VGG19();\n",
        "model.summary();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkgbZAHx2YvQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jng4x9l_YgqB"
      },
      "source": [
        "### 5. 성능 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PaUzdDZYgqI"
      },
      "outputs": [],
      "source": [
        "# 성능 확인\n",
        "width = 200\n",
        "height = 200\n",
        "channel = 3\n",
        "\n",
        "label_names = ['Daisy', 'Lavender', 'Lily', 'Rose', 'Sunflower']\n",
        "\n",
        "for i in range(10):\n",
        "    plt.figure(figsize=(2,2))\n",
        "\n",
        "    l = random.randrange(1,900)\n",
        "    \n",
        "    output = model.predict(x_test[l].reshape(1, width, height, channel))\n",
        "    \n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(x_test[l].reshape(width, height, channel))\n",
        "    \n",
        "    print('예측 : ' + label_names[np.argmax(output)] + ' / 정답 : ' + label_names[np.argmax(t_test[l])])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWkgnq9z2qdy"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-1Q--_iYgqT",
        "outputId": "d26c72c2-4ebf-4b17-855a-91aca1e0da29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 3s 85ms/step - loss: 2.8319 - accuracy: 0.4384\n",
            "test loss :  2.831933\n",
            "test accuracy :  43.841 %\n"
          ]
        }
      ],
      "source": [
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(x_test, t_test, verbose=1)\n",
        "print('test loss : ', round(loss, 6))\n",
        "print('test accuracy : ', round(accuracy*100, 3), '%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7MzxUVBdGOI"
      },
      "outputs": [],
      "source": [
        "# 학습된 모델 저장 \n",
        "\n",
        "# https://tykimos.github.io/2017/06/10/Model_Save_Load/\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "model.save('/content/ResNet501_1.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시각화\n",
        "\n",
        "https://stackoverflow.com/questions/41908379/keras-plot-training-validation-and-test-set-accuracy\n"
      ],
      "metadata": {
        "id": "7Ckh6MFZoMed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R-XZ-04EoOZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1Rylv057oUtw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}