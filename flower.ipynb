{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSwb2A8k_m1_"
      },
      "source": [
        "## 참고 자료\n",
        "\n",
        "- kaggle api colab으로 사용하기 - https://colab.research.google.com/github/corrieann/kaggle/blob/master/kaggle_api_in_colab.ipynb\n",
        "\n",
        "- image to dataset - https://towardsdatascience.com/loading-custom-image-dataset-for-deep-learning-models-part-1-d64fa7aaeca6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zq5NQccEdk7"
      },
      "source": [
        "### 1. kaggle api colab으로 사용하기\n",
        "- 이제 다운도 안받아도 된다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZkjwSQNQJhO"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pI1zHSkmUpvr"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload() # kaggle 홈페이지 > 오른쪽 위 프로필 > Settings > Create new token 해서 다운받은 json 파일\n",
        "# 본인 '각자' 다른 파일을 넣어줘야 합니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROtecG_IWLZ4"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8irHbfcsXNBr"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download -d utkarshsaxenadn/flower-classification-5-classes-roselilyetc\n",
        "# kaggle competitions download -c tpu-getting-started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLBwoPYoYZDk"
      },
      "outputs": [],
      "source": [
        "!unzip flower-classification-5-classes-roselilyetc.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yWv5a1JAMTc"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtjkoN1mEo6F"
      },
      "source": [
        "### 2. 데이터 다루기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym254fo__714"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.models import Sequential, Model\n",
        "from keras.applications.resnet import ResNet50, preprocess_input\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8033ERdA0Mc"
      },
      "outputs": [],
      "source": [
        "# 경로 체크 용\n",
        "\n",
        "img = mpimg.imread('/content/Flower Classification/Flower Classification/Training Data/Daisy/Daisy (1).jpeg')\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ADrq24LBfYQ"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH=224\n",
        "IMG_HEIGHT=224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ua-HkHBRCFoO"
      },
      "outputs": [],
      "source": [
        "# img -> dataset 함수\n",
        "def create_dataset(img_folder):\n",
        "\n",
        "    img_data_array=[]\n",
        "    class_name=[]\n",
        "\n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "\n",
        "            image_path= os.path.join(img_folder, dir1,  file)\n",
        "            image= cv2.imread(image_path)\n",
        "            b, g, r = cv2.split(image)\n",
        "            image = cv2.merge([r,g,b])\n",
        "            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "            image=np.array(image)\n",
        "            image = image.astype('float32')\n",
        "            image /= 255\n",
        "            img_data_array.append(image)\n",
        "            class_name.append(dir1)\n",
        "\n",
        "        print(\"Done \" + dir1)\n",
        "\n",
        "\n",
        "    target_dict={k: v for v, k in enumerate(np.unique(class_name))}\n",
        "    target_val=[target_dict[class_name[i]] for i in range(len(class_name))]\n",
        "    img_data_array = np.array(img_data_array) # araay -> nparray로 바꾸는 과정\n",
        "    return img_data_array, target_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRxt7_KvChHE"
      },
      "outputs": [],
      "source": [
        "x_train, t_train =create_dataset('/content/Flower Classification/Flower Classification/Training Data')\n",
        "x_test, t_test =create_dataset('/content/Flower Classification/Flower Classification/Testing Data')\n",
        "x_val, t_val =create_dataset('/content/Flower Classification/Flower Classification/Validation Data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2yaYbwwCz1Y"
      },
      "outputs": [],
      "source": [
        "# data test\n",
        "\n",
        "label_names = ['Daisy', 'Lavender', 'Lily', 'Rose', 'Sunflower']\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "for i in range(25):\n",
        "    l = random.randrange(1,5000)\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(x_train[l])\n",
        "    plt.xlabel(label_names[t_train[l]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRDsla03C3tE"
      },
      "outputs": [],
      "source": [
        "t_train = to_categorical(t_train)\n",
        "t_test = to_categorical(t_test)\n",
        "t_val = to_categorical(t_val)\n",
        "print('One-hot Vector 적용 후 t_val shape : ', t_val.shape)\n",
        "print('One-hot Vector 적용 후 t_train shape : ', t_train.shape)\n",
        "print('One-hot Vector 적용 후 t_test shape : ', t_test.shape)\n",
        "\n",
        "# 적용을 하지 않으면 아무래도 list 상태인 것 같다"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (0) 데이터 늘리기 beta\n",
        "\n",
        "- 문제점: 메모리오류 / 수정할 것: 쪼개서 추가하기\n",
        "- 사용할때 위의 코드에서 train dataset을 만드는 과정은 주석처리하고 사용해주시는게 좋습니다."
      ],
      "metadata": {
        "id": "0DoB1ts43vxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "mFy6GoQe3veQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#augmentation이 적용된 image들을 시각화 해주는 함수\n",
        "def show_aug_image(image, generator):\n",
        "\n",
        "    # ImageDataGenerator는 여러개의 image를 입력으로 받기 때문에 4차원으로 입력 해야함.\n",
        "    image_batch = np.expand_dims(image, axis=0)\n",
        "    generator.fit(image_batch)\n",
        "\n",
        "    return image_batch\n",
        "\n",
        "\n",
        "data_generator = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=(0.7, 1.3),\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    #rescale=1/255.0 # 학습시 적용, 시각화를 위해 임시로 주석처리\n",
        ")\n"
      ],
      "metadata": {
        "id": "xd9ySDcc4L7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img -> dataset 제너레이트 하면서\n",
        "def create_dataset_with_g(img_folder):\n",
        "\n",
        "    img_data_array=[]\n",
        "    class_name=[]\n",
        "\n",
        "    for dir1 in os.listdir(img_folder):\n",
        "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
        "\n",
        "            image_path= os.path.join(img_folder, dir1,  file)\n",
        "            image= cv2.imread(image_path)\n",
        "            b, g, r = cv2.split(image)\n",
        "            image = cv2.merge([r,g,b])\n",
        "            image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "            image=np.array(image)\n",
        "            image = image.astype('float32')\n",
        "            image /= 255\n",
        "            img_data_array.append(image)\n",
        "            class_name.append(dir1)\n",
        "\n",
        "            for i in range(4):\n",
        "              for l in show_aug_image(image, data_generator):\n",
        "                img_data_array.append(l)\n",
        "                class_name.append(dir1)\n",
        "\n",
        "\n",
        "        print(\"Done \" + dir1)\n",
        "\n",
        "\n",
        "    target_dict={k: v for v, k in enumerate(np.unique(class_name))}\n",
        "    target_val=[target_dict[class_name[i]] for i in range(len(class_name))]\n",
        "    img_data_array = np.array(img_data_array) # araay -> nparray로 바꾸는 과정\n",
        "    return img_data_array, target_val"
      ],
      "metadata": {
        "id": "otX1ToofteNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, t_train =create_dataset_with_g('./Flower Classification/Flower Classification/Training Data')"
      ],
      "metadata": {
        "id": "KysRdJXQ4M46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_train = to_categorical(t_train)\n",
        "print('One-hot Vector 적용 후 t_train shape : ', t_train.shape)"
      ],
      "metadata": {
        "id": "2NztJSyu4hKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (0-1) 웹 크롤링"
      ],
      "metadata": {
        "id": "9F1UtM0B-gTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- pixabay API - https://www.youtube.com/watch?v=vzvnGT6-gPA)\n",
        "- https://pixabay.com/api/docs/\n",
        "\n",
        "- 웹 크롤링 - https://kimcoder.tistory.com/259"
      ],
      "metadata": {
        "id": "_Ns0VgpP-8A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "# import key"
      ],
      "metadata": {
        "id": "krc-BKOL-oyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key = ' ' # 님들꺼 받아쓰셈 픽사베이에서\n",
        "keyword = 'daisy'\n",
        "pages = 2 # 한 페이지당 20"
      ],
      "metadata": {
        "id": "KS0oYiPG--kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = './crawled_img/'+ keyword + '/'\n",
        "\n",
        "# './crawled_img/'+keyword+'_'+str(maxImages)\n",
        "\n",
        "try:\n",
        "    # 중복되는 폴더 명이 없다면 생성\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "    # 중복된다면 문구 출력 후 프로그램 종료\n",
        "    else:\n",
        "        print('이전에 같은 [검색어, 이미지 수]로 다운로드한 폴더가 존재합니다.')\n",
        "        sys.exit(0)\n",
        "except OSError:\n",
        "    print ('os error')\n",
        "    sys.exit(0)"
      ],
      "metadata": {
        "id": "kXtJhe8f_NjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for page in range(1,int(pages)+1):\n",
        "    url = 'https://pixabay.com/api/?key='+key+'&q=' +keyword+'&image_type=photo&page='+str(page)\n",
        "\n",
        "    r = requests.get(url)\n",
        "    json_data = r.json()\n",
        "\n",
        "    for image in json_data['hits']:\n",
        "        name = image['id']\n",
        "        img_url = image['previewURL'] # largeImageURL(대) webformatURL(중) previewURL(소)\n",
        "        r = requests.get(img_url, stream=True)\n",
        "        with open(path + keyword + '(' + str(name) + ').jpg', 'wb') as f:\n",
        "            f.write(r.content)"
      ],
      "metadata": {
        "id": "Q6hVPraZ_OZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (0-2) Image 분류기\n"
      ],
      "metadata": {
        "id": "ZcFVZZPIDcJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from os import remove\n",
        "from  matplotlib import pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "\n",
        "# 모델 불러오기\n",
        "model2 = keras.models.load_model('C:\\model/ResNet152v2_b64_e10.h5') # 88% 정확도\n",
        "# 오류가 나면 '한글' 경로가 없는 절대경로로 입력해주세요"
      ],
      "metadata": {
        "id": "e9nwI8WsDkaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_folder = './Flower Classification_/Flower Classification/Training Data/Daisy' # 수정할 이미지 폴더 # Validation Data Testing Data\n",
        "\n",
        "img_label = 'Daisy' # 수정할 이미지의 라벨(이름) 'Daisy', 'Lavender', 'Lily', 'Rose', 'Sunflower'\n",
        "move_folder = './change/' + img_label +'/' # 이동할 이미지 폴더\n",
        "os.makedirs(move_folder) # 폴더가 이미 존재하면 실행 X\n",
        "\n",
        "amount = 1.8986970e-09 # 1.8986970e-09  1.2831312e-10 # 기준값. 건드리지 않는게 좋음\n",
        "IMG_WIDTH=224\n",
        "IMG_HEIGHT=224"
      ],
      "metadata": {
        "id": "sfhwOMArDrs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = ['Daisy', 'Lavender', 'Lily', 'Rose', 'Sunflower']\n",
        "\n",
        "\n",
        "worng = 0\n",
        "all_img = len(os.listdir(img_folder))\n",
        "\n",
        "print('총 파일 수: ', all_img, '\\n이미지 분류 시작\\n')\n",
        "\n",
        "for file in os.listdir(img_folder):\n",
        "    # all_img += 1\n",
        "    image_path= os.path.join(img_folder, file)\n",
        "    image= cv2.imread(image_path)\n",
        "    b, g, r = cv2.split(image)\n",
        "    image = cv2.merge([r,g,b])\n",
        "    image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "    image=np.array(image)\n",
        "    image = image.astype('float32')\n",
        "    image /= 255\n",
        "\n",
        "    output = model2.predict(image.reshape(1, IMG_WIDTH, IMG_WIDTH, 3), verbose=0) # 되려나\n",
        "\n",
        "    if(output[0][0] + output[0][1] + output[0][2] + output[0][3] + output[0][4] - output[0][label_names.index(img_label)]  > amount or\n",
        "       label_names[np.argmax(output)] != img_label):\n",
        "\n",
        "\n",
        "        worng +=1\n",
        "        plt.figure(figsize=(2,2))\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.imshow(image.reshape(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "\n",
        "        print('잘못된 이미지['+ file + ']\\n예측 : ' + label_names[np.argmax(output)] + ' / 정답 : ' + img_label, \"\\n\", output)\n",
        "        plt.show()\n",
        "        # remove(file) # 삭제\n",
        "\n",
        "        shutil.move(img_folder + '/' + file, move_folder + file)\n",
        "\n",
        "print('잘못된 이미지 개수: ', worng, \"/\",  all_img)"
      ],
      "metadata": {
        "id": "db4qVozZDxtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4nUY_ogXmAh"
      },
      "source": [
        "## (1) 기존 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vGNUB8dE5ae"
      },
      "source": [
        "### 3. model 부분"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfqW9ie8DJKN"
      },
      "outputs": [],
      "source": [
        "# model 부분\n",
        "\n",
        "width = 200\n",
        "height = 200\n",
        "channel = 3\n",
        "\n",
        "model = Sequential(name = 'CIFAR10_CNN')\n",
        "\n",
        "model.add(Conv2D(filters=100, kernel_size=(2, 2), padding= 'same', activation= 'relu',\n",
        "                input_shape=(width, height, channel)))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=200, kernel_size=(2, 2), padding= 'same', activation= 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=400, kernel_size=(2, 2), padding= 'same', activation= 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate = 0.001), metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sduZTV9E-e0"
      },
      "source": [
        "### 4. 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NE7DrQqDV8a"
      },
      "outputs": [],
      "source": [
        "# 학습하기\n",
        "model.fit(x_train, t_train, epochs=10, batch_size=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F69qo5-XFC0k"
      },
      "source": [
        "### 5. 성능 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwHOGVpBDgjz"
      },
      "outputs": [],
      "source": [
        "# 성능 확인\n",
        "width = 200\n",
        "height = 200\n",
        "channel = 3\n",
        "\n",
        "label_names = ['Daisy', 'Lavender', 'Lily', 'Rose', 'Sunflower']\n",
        "\n",
        "for i in range(10):\n",
        "    plt.figure(figsize=(2,2))\n",
        "\n",
        "    l = random.randrange(1,900)\n",
        "\n",
        "    output = model.predict(x_test[l].reshape(1, width, height, channel))\n",
        "\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(x_test[l].reshape(width, height, channel))\n",
        "\n",
        "    print('예측 : ' + label_names[np.argmax(output)] + ' / 정답 : ' + label_names[np.argmax(t_test[l])])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qz_3QrIfDhia"
      },
      "outputs": [],
      "source": [
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(x_test, t_test, verbose=1)\n",
        "print('test loss : ', round(loss, 6))\n",
        "print('test accuracy : ', round(accuracy*100, 3), '%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg-9TEshXskC"
      },
      "source": [
        "## (2) 강의 실습 모델1: ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rW4vRBy4jkw"
      },
      "outputs": [],
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(200,200,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqJ06JQi47_8"
      },
      "outputs": [],
      "source": [
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "predictions = Dense(5, activation='softmax')(x) # Dense = 클래스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tA4SAhhX52WA"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVKJnu8f62qM"
      },
      "outputs": [],
      "source": [
        "for layer in base_model.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7DuyO7y68KF"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# if one-hot -> loss = 'categorical_crossentropy'\n",
        "# 1D or 정수 인코딩 대상 = sparse_categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2EnXzdz7GvG"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ModelCheckpoint\n",
        "- https://blog.naver.com/combioai/221468928164"
      ],
      "metadata": {
        "id": "fH4CbqMrhZIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                           patience=5),\n",
        "             keras.callbacks.ModelCheckpoint(filepath='C:\\model/best_model.h5', # 적당한 폴더에 사용하길 바람\n",
        "                                             monitor='val_loss',\n",
        "                                             save_best_only=True)]"
      ],
      "metadata": {
        "id": "wxFDrG7thYrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HiTFKhA7Pb6"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train, t_train, batch_size= 64, epochs=10, validation_data=(x_val, t_val), callbacks=callbacks)\n",
        "#  callbacks=[early_stopping] 기존방식\n",
        "#  callbacks ModelCheckpoint 방식"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('C:\\model/best_model.h5') # 절대경로로 작성해야 오류가 적음"
      ],
      "metadata": {
        "id": "UfFfkEtds8II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5HdcZXndpzl"
      },
      "outputs": [],
      "source": [
        "# 불러오기\n",
        "\n",
        "# 학습을 시키지 않아도 됨\n",
        "from keras.models import load_model\n",
        "model2 = load_model('/content/ResNet50_1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bARpnF0eFOV"
      },
      "source": [
        "GoogleNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTsrA9TseEdx"
      },
      "outputs": [],
      "source": [
        "from keras.applications import inception_v3\n",
        "model = inception_v3.InceptionV3(weights='imagenet', include_top=True)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtf4mOd2e1Ee"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8r0s8nNuSU8"
      },
      "source": [
        "## (2) 강의 실습 모델3: VGG19Net\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HuQ1i_OuvD3"
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg19 import VGG19\n",
        "tf.keras.applications.VGG19(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\",\n",
        ")\n",
        "model=VGG19();\n",
        "model.summary();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jng4x9l_YgqB"
      },
      "source": [
        "### 5. 성능 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PaUzdDZYgqI"
      },
      "outputs": [],
      "source": [
        "# 성능 확인\n",
        "width = 200\n",
        "height = 200\n",
        "channel = 3\n",
        "\n",
        "label_names = ['Daisy', 'Lavender', 'Lily', 'Rose', 'Sunflower']\n",
        "\n",
        "for i in range(10):\n",
        "    plt.figure(figsize=(2,2))\n",
        "\n",
        "    l = random.randrange(1,900)\n",
        "\n",
        "    output = model.predict(x_test[l].reshape(1, width, height, channel))\n",
        "\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(x_test[l].reshape(width, height, channel))\n",
        "\n",
        "    print('예측 : ' + label_names[np.argmax(output)] + ' / 정답 : ' + label_names[np.argmax(t_test[l])])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWkgnq9z2qdy"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-1Q--_iYgqT"
      },
      "outputs": [],
      "source": [
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(x_test, t_test, verbose=1)\n",
        "print('test loss : ', round(loss, 6))\n",
        "print('test accuracy : ', round(accuracy*100, 3), '%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7MzxUVBdGOI"
      },
      "outputs": [],
      "source": [
        "# 학습된 모델 저장\n",
        "\n",
        "# https://tykimos.github.io/2017/06/10/Model_Save_Load/\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "model.save('/content/ResNet501_1.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시각화\n",
        "\n",
        "https://stackoverflow.com/questions/41908379/keras-plot-training-validation-and-test-set-accuracy\n"
      ],
      "metadata": {
        "id": "7Ckh6MFZoMed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R-XZ-04EoOZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1Rylv057oUtw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}